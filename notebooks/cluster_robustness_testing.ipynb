{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "K-means is initiated using a random process, and therefore can give different answers based on the random initiation. It is important we make sure our k-means setup is robust and returns very similar results every time. K-means returning inconsistent results can be indicative of a few things. It can often be a symptom of the value of k being too small, or it can mean that `n_init` is not high enough. The `n_init` parameter is how many times k-means clustering is performed for each call of the k-means function. The initiation with the best final result (most compact clusters) will be chosen as the final output. Computation time increases with `n_init`, but the final output is likely to be more robust. When utilizing Wasserstein distance, inconsistent results could also be a symptom of `tol` being too large. As mentioned earlier, `tol` will likely need to be increased by a few orders of magnitude when using Wasserstein distance. You may need to experiment with this parameter to find a value that can deliver consistent results and still is able to complete in a reasonable amount of time.  \n",
    "\n",
    "In previous works ([Tselioudis et al. 2013](https://journals.ametsoc.org/view/journals/clim/26/19/jcli-d-13-00024.1.xml)) have tested for a robust k-means setup by performing the clustering three times for the final k and checking that the correlations between the cluster centers is > 0.8.\n",
    "\n",
    "This script will perform k-means clustering `n_trials` times, and test if correlations between the cluster centers is greater than `correlation_limit`, where `n_trials` and `correlation_limit` are user-defined parameters. Start with `n_trials=3` and `correlation_limit=0.8`, but if computation power allows, it may be worth experimenting with more stringent constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein package is not installed so wasserstein distance cannot be used. Attempting to use wassertein distance will raise an error.\n",
      "To use wasserstein distance please install the wasserstein package in your environment: https://pypi.org/project/Wasserstein/ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Functions import emd_means, euclidean_kmeans, plot_hists, open_and_process, plot_rfo\n",
    "import logging as lgr\n",
    "import dask\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Variables and Opening Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the variables necessary to begin using the toy ISCCP dataset included with this cookbook. To start off leave these variables alone, but later on feel free to experiment and change `n_trials` and `correlation_limit`. Also, free to mess around with the k-means properties. Try increasing `tol` or decreasing `n_init`, try an inappropriate value of k, or random initiations versus `k-means++` initiation. What k-means properties result in inconsistent results? Change `plot_cr_centers` and/or `plot_rfo_maps` to true to plot the clustering results from each trial and examine how similar they are. It is also worth noting that just because a k-means setup is robust for the relatively small ISCCP dataset we're using, does not mean it will be robust for much larger datasets.\n",
    "\n",
    "If running locally with your own dataset, you will need to change many of the variables these to match and point towards your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data to cluster\n",
    "data_path = \"./ISCCP_toy_data.nc\"\n",
    "\n",
    "# Path to the directory you wish to save plots in if running as a script, if None plots will only be shown and not saved. Enter as String\n",
    "save_path = None\n",
    "save_prefix = None  # prefix to put into the name of each plot to distinguish different runs of this script\n",
    "\n",
    "# Variable name of data to cluster in data_path\n",
    "# Name of tau dimension for var_name\n",
    "# Name of height/pressure dimension for var_name\n",
    "var_name =  'n_pctaudist' \n",
    "tau_var_name =  'levtau' \n",
    "ht_var_name =  'levpc'\n",
    "lat_var_name = 'lat'\n",
    "lon_var_name = 'lon'\n",
    "\n",
    "# Does this dataset use cloud top height or cloud top pressure? enter \"h\" for height or \"p\" for pressure\n",
    "height_or_pressure = 'p'\n",
    "\n",
    "# kmeans properties\n",
    "k = 4   # number of cluster to create\n",
    "tol = 0.001   # maximum change in inertia values between kmeans iterations to declare convergence. should be higher if using wasserstein distance\n",
    "max_iter = 100   # maximum number of k-means iterations to preform for each initiation\n",
    "init = 'k-means++'    # initialization technique for kmeans, can be 'k-means++', 'random', or initial clusters to use of shape (k, n_tau_bins * n_pressure_bins)\n",
    "n_init = 10    # number of initiations of the k-means algorithm. The final result will be the initiation with the lowest calculated inertia\n",
    "gpu = False  # If the user has an Nvidia GPU, euclidean clustering can br preformed on it for a very significant speed up. CUPY/CUML must be installed in conda environment.\n",
    "\n",
    "# k sensitivity testing properties\n",
    "n_trials = 3 # how many times to preform the clustering with above properties\n",
    "correlation_limit = 0.8 # Lowest acceptable correlation between the CRs through n_trials\n",
    "\n",
    "# Want to see the results of clustering for each trial? Set one or both of these to true. \n",
    "plot_cr_centers = False\n",
    "plot_rfo_maps = False\n",
    "\n",
    "# Choose whether to use a euclidean or wasserstein distance kmeans algorithm\n",
    "wasserstein_or_euclidean = \"euclidean\"\n",
    "\n",
    "# Minimum and Maximum longitudes and latitudes entered as list, or None for entire range: Ex [-65,65]\n",
    "lat_range = [-90,90]\n",
    "lon_range = [-180,180]\n",
    "\n",
    "# Time Range min and max, or None for all time, entered as list of str: Ex. [\"2003-03-01\", \"2004-07-01\"] or ['2003','2007']\n",
    "time_range = None\n",
    "\n",
    "# Use data only over land or over ocean\n",
    "# Set to 'L' for land only, 'O' for ocean only, or False for both land and ocean\n",
    "only_ocean_or_land = False\n",
    "# Does this dataset have a built in variable for land fraction? if so enter variable name as a string, otherwise cartopy will be used to mask out land or water\n",
    "land_frac_var_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Proprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: Opening dataset:\n",
      "INFO:root: Opening finished. Beginning preprocessing:\n",
      "INFO:root: Reshaping data to shape (n_histograms, n_tau_bins* n_pc_bins):\n",
      "INFO:root: Reading data into memory:\n",
      "INFO:root: Finished preprocessing:\n"
     ]
    }
   ],
   "source": [
    "# Logging level, set to \"INFO\" for information about what the code is doing, otherwise keep at \"WARNING\"\n",
    "logging_level = 'INFO'\n",
    "\n",
    "# Setting up logger\n",
    "lgr.basicConfig(level=lgr.DEBUG)\n",
    "# Concatenating save_path and save prefix\n",
    "if save_path != None: save_path = save_path + save_prefix\n",
    "# Avoid creation of large chunks with dask\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": False})\n",
    "# Automatically setting premade_cloud_regimes to none because this file does not need them. Do not Change.\n",
    "premade_cloud_regimes = None\n",
    "\n",
    "# Opening and preprocessing data\n",
    "mat, valid_indicies, ds, histograms, weights = open_and_process(data_path, k, tol, max_iter, init, n_init, var_name, tau_var_name, ht_var_name, lat_var_name, lon_var_name, height_or_pressure, wasserstein_or_euclidean, premade_cloud_regimes, lat_range, lon_range, time_range, only_ocean_or_land, land_frac_var_name, cluster = False)\n",
    "\n",
    "# Setting up array to hold reults of every clustering trial\n",
    "cl_trials = np.empty((n_trials,k,mat.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering and Checking Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: This K-means setup was insensitive to the initial centroids used\n"
     ]
    }
   ],
   "source": [
    "# Preform clustering with specified distance metric, n_trials times and record the resultant cloud regimes each time\n",
    "for trial in range(n_trials):\n",
    "    if wasserstein_or_euclidean == \"wasserstein\":\n",
    "        cl_trials[trial], cluster_labels_temp, throw_away, throw_away2 = emd_means(mat, k, tol, init, n_init, ds, tau_var_name, ht_var_name, hard_stop = 45, weights = None)\n",
    "    elif wasserstein_or_euclidean == \"euclidean\":\n",
    "        cl_trials[trial], cluster_labels_temp = euclidean_kmeans(k, init, n_init, mat, max_iter, tol, gpu)\n",
    "    else: raise Exception ('Invalid option for wasserstein_or_euclidean. Please enter \"wasserstein\", \"euclidean\"')\n",
    "\n",
    "    if plot_cr_centers or plot_rfo_maps:\n",
    "        # Reshaping cluster_labels_temp to original shape of ds and reinserting NaNs in the original places, so plot can be made if needed\n",
    "        cluster_labels = np.full(len(histograms), np.nan, dtype=np.int32)\n",
    "        cluster_labels[valid_indicies]=cluster_labels_temp\n",
    "        cluster_labels = xr.DataArray(data=cluster_labels, coords={\"spacetime\":histograms.spacetime},dims=(\"spacetime\") )\n",
    "        cluster_labels = cluster_labels.unstack()\n",
    "\n",
    "        if plot_cr_centers:\n",
    "            plot_hists(cluster_labels, k, ds, ht_var_name, tau_var_name, valid_indicies, mat, cluster_labels_temp, height_or_pressure, save_path)\n",
    "\n",
    "        if plot_rfo_maps:\n",
    "            plot_rfo(cluster_labels,k,ds, save_path)\n",
    "\n",
    "# Testing the correlation coefficients of resultant CRs across k-means runs\n",
    "cor_coefs = np.zeros((k,k))\n",
    "failures = 0\n",
    "for trial1 in range(n_trials):\n",
    "    cl1 = cl_trials[trial1]\n",
    "    for trial2 in range(n_trials):\n",
    "        cl2 = cl_trials[trial2]\n",
    "        for i in range (k):\n",
    "            for x in range (k):\n",
    "                cor_coefs[i,x] = np.corrcoef(cl1[i].flatten(),cl2[x].flatten())[0,1]\n",
    "        max_cors = np.max(cor_coefs, axis=1)\n",
    "        if np.min(max_cors) < correlation_limit: failures += 1\n",
    "if failures > 0:\n",
    "    print(f\"Failed robustness testing. {failures} centroids have a correlation of less than {correlation_limit} with the other k-means initiations\")\n",
    "else:\n",
    "    print('Success: This K-means setup was insensitive to the initial centroids used')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're happy with the results and confident the k-means setup is robust, run the next cell to save the clustering results from the last trial. Then open the next file plot_and_analyze.ipynb and we'll explore some further data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./toy_ISCCP_cluster_centers.npy\", cl_trials[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c82514a3a5bab9dc8fa7ef0461220e9cb3d38a64f7d511dfc68fe93fbd887e3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('clustering': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python 3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "Python3"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
